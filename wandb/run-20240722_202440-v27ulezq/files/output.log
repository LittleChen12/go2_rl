Traceback (most recent call last):
  File "./train.py", line 27, in <module>
    train(args)
  File "./train.py", line 17, in train
    ppo_runner, train_cfg = task_registry.make_alg_runner(env=env, name=args.task, args=args)
  File "/home/pi/Downloads/LocomotionWithNP3O-master/utils/task_registry.py", line 118, in make_alg_runner
    runner = runner_class(env, train_cfg_dict, log_dir, device=args.rl_device)
  File "/home/pi/Downloads/LocomotionWithNP3O-master/runner/on_constraint_policy_runner.py", line 91, in __init__
    self.env.reset()
  File "/home/pi/Downloads/LocomotionWithNP3O-master/envs/legged_robot.py", line 878, in reset
    obs,_,_, _, _,_= self.step(
  File "/home/pi/Downloads/LocomotionWithNP3O-master/envs/legged_robot.py", line 382, in step
    self.post_physics_step()
  File "/home/pi/Downloads/LocomotionWithNP3O-master/envs/legged_robot.py", line 523, in post_physics_step
    self.compute_observations()
  File "/home/pi/Downloads/LocomotionWithNP3O-master/envs/legged_robot.py", line 406, in compute_observations
    self.command_input = torch.cat(
TypeError: cat() received an invalid combination of arguments - got (Tensor, dim=int), but expected one of:
 * (tuple of Tensors tensors, int dim, *, Tensor out)
 * (tuple of Tensors tensors, name dim, *, Tensor out)
ppo with teacher actor
no imitation
MixedMlpBarlowTwinsActor(
  (mlp_encoder): Sequential(
    (0): Linear(in_features=225, out_features=512, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ELU(alpha=1.0)
    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (5): Linear(in_features=256, out_features=128, bias=True)
    (6): ELU(alpha=1.0)
    (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (8): Linear(in_features=128, out_features=23, bias=True)
  )
  (actor): MixedMlp(
    (gate): Sequential(
      (0): Linear(in_features=68, out_features=128, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=4, bias=True)
    )
  )
  (obs_encoder): Sequential(
    (0): Linear(in_features=45, out_features=256, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (5): Linear(in_features=128, out_features=16, bias=True)
  )
  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
running with imi loss off
num_transitions_per_env: 24
cost_shape: [9]
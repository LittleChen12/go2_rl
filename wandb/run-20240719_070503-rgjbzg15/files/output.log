ppo with teacher actor
no imitation
MixedMlpBarlowTwinsActor(
  (mlp_encoder): Sequential(
    (0): Linear(in_features=225, out_features=512, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ELU(alpha=1.0)
    (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (5): Linear(in_features=256, out_features=128, bias=True)
    (6): ELU(alpha=1.0)
    (7): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (8): Linear(in_features=128, out_features=23, bias=True)
  )
  (actor): MixedMlp(
    (gate): Sequential(
      (0): Linear(in_features=68, out_features=128, bias=True)
      (1): ELU(alpha=1.0)
      (2): Linear(in_features=128, out_features=128, bias=True)
      (3): ELU(alpha=1.0)
      (4): Linear(in_features=128, out_features=4, bias=True)
    )
  )
  (obs_encoder): Sequential(
    (0): Linear(in_features=45, out_features=256, bias=True)
    (1): ELU(alpha=1.0)
    (2): Linear(in_features=256, out_features=128, bias=True)
    (3): ELU(alpha=1.0)
    (4): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
    (5): Linear(in_features=128, out_features=16, bias=True)
  )
  (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)
)
running with imi loss off
Traceback (most recent call last):
  File "./train.py", line 27, in <module>
    train(args)
  File "./train.py", line 18, in train
    ppo_runner.learn(num_learning_iterations=train_cfg.runner.max_iterations, init_at_random_ep_len=True)
  File "/home/pi/Downloads/LocomotionWithNP3O-master/runner/on_constraint_policy_runner.py", line 175, in learn
    mean_value_loss,mean_cost_value_loss,mean_viol_loss,mean_surrogate_loss, mean_imitation_loss = self.alg.update()
  File "/home/pi/Downloads/LocomotionWithNP3O-master/algorithm/np3o.py", line 253, in update
    loss.backward()
  File "/home/pi/anaconda3/envs/HIT/lib/python3.8/site-packages/torch/_tensor.py", line 525, in backward
    torch.autograd.backward(
  File "/home/pi/anaconda3/envs/HIT/lib/python3.8/site-packages/torch/autograd/__init__.py", line 267, in backward
    _engine_run_backward(
  File "/home/pi/anaconda3/envs/HIT/lib/python3.8/site-packages/torch/autograd/graph.py", line 744, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 454.00 MiB. GPU